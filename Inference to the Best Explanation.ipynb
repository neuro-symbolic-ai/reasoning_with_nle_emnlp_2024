{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wV77S90jvsO0"
   },
   "source": [
    "## Inference to the Best Explanation (IBE) in Large Language Models (LLMs)\n",
    "\n",
    "IBE-Eval estimates the plausibility of natural language explanations through a combination of explicit logical and linguistic features. It operates on top of natural language explanations generated by Large Language Models using a combination of hard and soft critique models as a proxy to assess consistency, parsimony, coherence, and uncertainty.\n",
    "\n",
    "<img src=\"figures/ibe.png\" height=\"400\" class=\"center\">\n",
    "\n",
    "## IBE Evaluation Criteria\n",
    "\n",
    "- *Consistency (Hard Critique).* Verify whether the explanation is logically valid. Given a hypothesis, composed of a premise pi, a conclusion ci, and an explanation consisting of a set of statements E =s1,...,si, we define E to be logically consistent if pi ∪ E ⊨ ci. Specifically, an explanation is logically consistent if it is possible to build a deductive proof linking premise and conclusion.\n",
    "\n",
    "- *Parsimony (Soft Critique).* The parsimony principle, also known as Ockham’s razor, favors the selection of the simplest explanation consisting of the fewest elements and assumptions. Adopt two metrics as a proxy of parsimony, namely proof depth, and concept drift.  Concept drift, denoted as Drift, is defined as the\n",
    "number of additional concepts and entities, outside the ones appearing in the hypothesis (i.e., premise and conclusion), that are introduced by the LLM to support the entailment. \n",
    "\n",
    "\\begin{equation}\n",
    "Drift(h) = |Noun_{E} - (Noun_{p} \\cup Noun_{c})\n",
    "\\end{equation}\n",
    "\n",
    "- *Coherence (Soft Critique).* Attempts to measure the logical relations within individual explanatory statements and implications. An explanation can be formally consistent on the surface while still including implausible or ungrounded intermediate assumptions. Coherence evaluate the quality of each intermediate If-Then implication by measuring the entailment strength between the If and Then clauses. To this end, we employ a fine-tuned natural language inference (NLI) model. Let S\n",
    "be a set of explanation steps, where each step s consists of an If-Then statement, s = (Ifs,Thens). For a given step si, let ES(si) denote the entailment score obtained via the NLI model between Ifs and Thens clauses. The step-wise entailment score SWE(S) is then calculated as the averaged sum of the entailment scores across all explanation steps |S|.\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{SWE}(S) = \\frac{1}{|S|}\\sum_{i=1}^{|S|} \\text{ES}(s_i)\n",
    "\\end{equation}\n",
    "\n",
    "- *Uncertainty (Soft Critique).* Finally, we consider the linguistic certainty expressed in the generated explanation as a proxy for plausibility. Hedging words such as probably, might be, could be, etc typically signal ambiguity and are often used when the truth condition of a statement is unknown or improbable. Pei and Jurgens (2021) found that the strength of scientific claims in research papers is strongly correlated with the use of direct language. In contrast, they found that the use of hedging language suggested that the veracity of the claim was weaker or highly contextualized. To measure the linguistic certainty we use a fine-tuned sentence-level RoBERTa model.\n",
    "\n",
    "## Results\n",
    "\n",
    "<div>\n",
    "<img src=\"figures/ibe_results.png\" height=\"265\">\n",
    "<img src=\"figures/ibe_results_1.png\" height=\"265\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try with GPT-3.5-turbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Explanations for the hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19832,
     "status": "ok",
     "timestamp": 1731333973598,
     "user": {
      "displayName": "Marco Valentino",
      "userId": "16985191850808964577"
     },
     "user_tz": 0
    },
    "id": "fHzztvy0vsO8",
    "outputId": "969bf508-276b-40e4-9dcc-4ca95d563059"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explanation 1:\n",
      "\n",
      "Hypothesis I blew into the baloon.\n",
      "Conlusion The balloon expanded.\n",
      "\n",
      "Step 1: IF I blow into a balloon, THEN air is forced into the balloon.\n",
      "Assumption: Blowing into a balloon introduces air into its interior.\n",
      "\n",
      "Step 2: IF air is forced into the balloon, THEN the volume of the balloon increases.\n",
      "Assumption: Adding air to a flexible object like a balloon causes it to expand.\n",
      "\n",
      "Step 3: IF the volume of the balloon increases, THEN the balloon expands.\n",
      "Assumption: The physical property of a balloon allows it to expand when filled with air.\n",
      "\n",
      "Step 4: Therefore, since I blew into the balloon, the air was forced into it, leading to an increase in volume, which resulted in the balloon expanding.\n",
      "\n",
      "Explanation 2:\n",
      "\n",
      "Hypothesis I pricked the baloon.\n",
      "Conclusion The balloon expanded.\n",
      "\n",
      "Step 1: IF I prick a balloon, THEN it can cause the air inside to escape rapidly.\n",
      "Assumption: Pricking a balloon creates a hole that allows the air inside to exit.\n",
      "\n",
      "Step 2: IF the air inside the balloon escapes rapidly, THEN the balloon may initially expand before it deflates.\n",
      "Assumption: When air escapes from a balloon, the pressure difference can cause the balloon to momentarily expand before it loses its shape.\n",
      "\n",
      "Step 3: IF the balloon expands, THEN it may appear larger for a brief moment.\n",
      "Assumption: The physical properties of a balloon allow it to change size based on the pressure of the air inside it.\n",
      "\n",
      "Step 4: IF the balloon appears larger, THEN it can be perceived as having expanded.\n",
      "Assumption: The visual perception of size change is interpreted as expansion.\n",
      "\n",
      "Step 5: Therefore, since I pricked the balloon, the air escaped rapidly, causing the balloon to momentarily expand before deflating, leading to the conclusion that the balloon expanded.\n"
     ]
    }
   ],
   "source": [
    "# Import the  critique models\n",
    "from critique import CoherenceCritique\n",
    "from critique import ParsimonyCritique\n",
    "from critique import UncertaintyCritique\n",
    "\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Import the generative GPT model\n",
    "from generation.generative_model import GPT\n",
    "import yaml\n",
    "\n",
    "\n",
    "# Initialise the generative model (i.e. GPT-4o-mini)\n",
    "with open('config.yaml', 'r') as file:\n",
    "     config = yaml.safe_load(file)\n",
    "     api_key = config.get('gpt-3.5-turbo', {}).get('api_key')\n",
    "\n",
    "llm = GPT('gpt-4o-mini', api_key)\n",
    "\n",
    "\n",
    "# First hypothesis (change to premise)\n",
    "hypothesis_1 = \"I blew into the baloon.\"\n",
    "conclusion_1 =  \"The balloon expanded.\"\n",
    "\n",
    "# Second hypothesis (change to premise)\n",
    "hypothesis_2 = \"I pricked the baloon.\"\n",
    "conclusion_2 =  \"The balloon expanded.\"\n",
    "\n",
    "# Prompt the model to generate the explanation for the first hypothesis\n",
    "explanation_1 = llm.generate(\n",
    "             model_prompt_dir = 'ibe',\n",
    "             prompt_name = \"generate_explanation_prompt.txt\",\n",
    "             hypothesis = hypothesis_1,\n",
    "             conclusion = conclusion_1\n",
    "         )\n",
    "print(f\"\\nExplanation 1:\\n\\nHypothesis {hypothesis_1}\\nConlusion {conclusion_1}\\n\\n{explanation_1}\")\n",
    "\n",
    "\n",
    "# Prompt the model to generate the explanation for the first hypothesis\n",
    "explanation_2 = llm.generate(\n",
    "             model_prompt_dir = 'ibe',\n",
    "             prompt_name = \"generate_explanation_prompt.txt\",\n",
    "             hypothesis = hypothesis_2,\n",
    "             conclusion = conclusion_2\n",
    "         )\n",
    "print(f\"\\nExplanation 2:\\n\\nHypothesis {hypothesis_2}\\nConclusion {conclusion_2}\\n\\n{explanation_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate explanations via soft critique models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7619,
     "status": "ok",
     "timestamp": 1731334017967,
     "user": {
      "displayName": "Marco Valentino",
      "userId": "16985191850808964577"
     },
     "user_tz": 0
    },
    "id": "TFIqeRU7vsO-",
    "outputId": "1d06df47-1198-48e7-b44a-e3a25a7ed0db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/tokenization_auto.py:786: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py:469: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Critique Evaluation\n",
      "\n",
      " ================ Coherence ================\n",
      "\n",
      "Explanation 1:  {'entailment': 0.8321771919727325, 'neutral': 0.15723474323749542, 'contradiction': 0.010588052682578564, 'score': 0.821589139290154}\n",
      "Explanation 2:  {'entailment': 0.21366439014673233, 'neutral': 0.7775339881579081, 'contradiction': 0.008801604465891918, 'score': 0.2048627856808404}\n",
      "Coherence comparision: Explanation 1: 0.821589139290154 vs. Explanation 2: 0.2048627856808404\n",
      "Explanation 1 is therefore more coherent than Explanation 2.\n",
      "\n",
      "================ Parsimony ================\n",
      "\n",
      "Explanation 1:  {'score': 3}\n",
      "Explanation 2:  {'score': 4}\n",
      "\n",
      "Parsimony comparision: Explanation 1: 3 vs. Explanation 2: 4\n",
      "Explanation 1 is therefore more parsimonious than Explanation 2.\n",
      "\n",
      "================ Uncertainty ================\n",
      "\n",
      "Explanation 1:  {'score': 1.0384624799092612}\n",
      "Explanation 2:  {'score': 1.1498368382453918}\n",
      "\n",
      "Uncertainty comparision: Explanation 1: 1.0384624799092612 vs. Explanation 2: 1.1498368382453918\n",
      "Explanation 2 is therefore more uncertain than Explanation 1.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialise the soft critique models\n",
    "coherence = CoherenceCritique()\n",
    "parsimony = ParsimonyCritique()\n",
    "uncertainty = UncertaintyCritique()\n",
    "\n",
    "print(\"Soft Critique Evaluation\")\n",
    "# Calculate and display soft critique scores\n",
    "\n",
    "# Coherence Metrics\n",
    "exp1_coherence = coherence.critique(explanation_1)\n",
    "exp2_coherence = coherence.critique(explanation_2)\n",
    "\n",
    "print(\"\\n ================ Coherence ================\\n\")\n",
    "\n",
    "print(\"Explanation 1: \", exp1_coherence)\n",
    "print(\"Explanation 2: \", exp2_coherence)\n",
    "\n",
    "print(f\"Coherence comparision: Explanation 1: {exp1_coherence['score']} vs. Explanation 2: {exp2_coherence['score']}\")\n",
    "\n",
    "if exp1_coherence['score'] > exp2_coherence['score']:\n",
    "    print(\"Explanation 1 is therefore more coherent than Explanation 2.\")\n",
    "else:\n",
    "    print(\"Explanation 2 is the most coherente than Explanation 1.\")\n",
    "\n",
    "# Parsimony Metrics\n",
    "exp1_parsimony = parsimony.critique(hypothesis_1, conclusion_1, explanation_1)\n",
    "exp2_parsimony = parsimony.critique(hypothesis_2, conclusion_2, explanation_2)\n",
    "\n",
    "print(\"\\n================ Parsimony ================\\n\")\n",
    "\n",
    "print(\"Explanation 1: \", exp1_parsimony)\n",
    "print(\"Explanation 2: \", exp2_parsimony)\n",
    "\n",
    "print(f\"\\nParsimony comparision: Explanation 1: {exp1_parsimony['score']} vs. Explanation 2: {exp2_parsimony['score']}\")\n",
    "\n",
    "if exp1_parsimony['score'] < exp2_parsimony['score']:\n",
    "    print(\"Explanation 1 is therefore more parsimonious than Explanation 2.\")\n",
    "else:\n",
    "    print(\"Explanation 2 is therefore more parsimonious than Explanation 1.\")\n",
    "\n",
    "# Uncertainty Metrics\n",
    "exp1_uncertainty = uncertainty.critique(explanation_1)\n",
    "exp2_uncertainty = uncertainty.critique(explanation_2)\n",
    "\n",
    "print(\"\\n================ Uncertainty ================\\n\")\n",
    "\n",
    "print(\"Explanation 1: \", exp1_uncertainty)\n",
    "print(\"Explanation 2: \", exp2_uncertainty)\n",
    "\n",
    "print(f\"\\nUncertainty comparision: Explanation 1: {exp1_uncertainty['score']} vs. Explanation 2: {exp2_uncertainty['score']}\")\n",
    "\n",
    "if exp1_uncertainty['score'] > exp2_uncertainty['score']:\n",
    "    print(\"Explanation 1 is therefore more uncertain than Explanation 2.\")\n",
    "else:\n",
    "    print(\"Explanation 2 is therefore more uncertain than Explanation 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try with GPT-4-o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Explanations for the hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6544,
     "status": "ok",
     "timestamp": 1731334043473,
     "user": {
      "displayName": "Marco Valentino",
      "userId": "16985191850808964577"
     },
     "user_tz": 0
    },
    "id": "UmW-kKd1iliL",
    "outputId": "54049b54-198f-4089-c245-674456265131"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Explanation 1:\n",
      "\n",
      "Hypothesis I blew into the baloon.\n",
      "Conlusion The balloon expanded.\n",
      "\n",
      "Step 1: IF I blow into a balloon, THEN air is forced into the balloon.\n",
      "Assumption: Blowing into a balloon introduces air into its interior.\n",
      "\n",
      "Step 2: IF air is forced into the balloon, THEN the volume of air inside the balloon increases.\n",
      "Assumption: Adding air to a confined space increases the amount of air present in that space.\n",
      "\n",
      "Step 3: IF the volume of air inside the balloon increases, THEN the balloon will expand.\n",
      "Assumption: Balloons are designed to stretch and expand when filled with air or gas.\n",
      "\n",
      "Step 4: Therefore, since I blew into the balloon, the air was forced into it, leading to an increase in volume, which caused the balloon to expand.\n",
      "\n",
      "Explanation 2:\n",
      "\n",
      "Hypothesis I pricked the baloon.\n",
      "Conclusion The balloon expanded.\n",
      "\n",
      "Step 1: IF I prick a balloon, THEN it can cause the air inside the balloon to escape.\n",
      "Assumption: Pricking a balloon creates a hole, allowing the air to exit.\n",
      "\n",
      "Step 2: IF the air inside the balloon escapes, THEN the balloon may change its shape or size.\n",
      "Assumption: Balloons are flexible and can change shape based on the amount of air inside them.\n",
      "\n",
      "Step 3: IF the balloon changes its shape or size, THEN it may appear to expand or contract depending on the pressure difference.\n",
      "Assumption: The visual perception of a balloon can be influenced by the air pressure inside it and the surrounding environment.\n",
      "\n",
      "Step 4: IF the balloon appears to expand, THEN it may give the impression that it has expanded.\n",
      "Assumption: The visual effect of a balloon can create the illusion of expansion when air is escaping or when the balloon is manipulated.\n",
      "\n",
      "Step 5: Therefore, since I pricked the balloon, causing the air to escape, it may have changed its shape or size, leading to the impression that the balloon expanded.\n"
     ]
    }
   ],
   "source": [
    "# Import the  critique models\n",
    "from critique import CoherenceCritique\n",
    "from critique import ParsimonyCritique\n",
    "from critique import UncertaintyCritique\n",
    "\n",
    "from transformers.utils import logging\n",
    "logging.set_verbosity(logging.CRITICAL)\n",
    "\n",
    "# Import the generative GPT model\n",
    "from generation.generative_model import GPT\n",
    "import yaml\n",
    "\n",
    "\n",
    "# Initialise the generative model (i.e. GPT-4o)\n",
    "with open('config.yaml', 'r') as file:\n",
    "     config = yaml.safe_load(file)\n",
    "     api_key = config.get('gpt-4o', {}).get('api_key')\n",
    "\n",
    "llm = GPT('gpt-4o-mini', api_key)\n",
    "\n",
    "\n",
    "# First hypothesis (change to premise)\n",
    "hypothesis_1 = \"I blew into the baloon.\"\n",
    "conclusion_1 =  \"The balloon expanded.\"\n",
    "\n",
    "# Second hypothesis (change to premise)\n",
    "hypothesis_2 = \"I pricked the baloon.\"\n",
    "conclusion_2 =  \"The balloon expanded.\"\n",
    "\n",
    "# Prompt the model to generate the explanation for the first hypothesis\n",
    "explanation_1 = llm.generate(\n",
    "             model_prompt_dir = 'ibe',\n",
    "             prompt_name = \"generate_explanation_prompt.txt\",\n",
    "             hypothesis = hypothesis_1,\n",
    "             conclusion = conclusion_1\n",
    "         )\n",
    "print(f\"\\nExplanation 1:\\n\\nHypothesis {hypothesis_1}\\nConlusion {conclusion_1}\\n\\n{explanation_1}\")\n",
    "\n",
    "\n",
    "# Prompt the model to generate the explanation for the first hypothesis\n",
    "explanation_2 = llm.generate(\n",
    "             model_prompt_dir = 'ibe',\n",
    "             prompt_name = \"generate_explanation_prompt.txt\",\n",
    "             hypothesis = hypothesis_2,\n",
    "             conclusion = conclusion_2\n",
    "         )\n",
    "print(f\"\\nExplanation 2:\\n\\nHypothesis {hypothesis_2}\\nConclusion {conclusion_2}\\n\\n{explanation_2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate explanations via soft critique models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8417,
     "status": "ok",
     "timestamp": 1731334056380,
     "user": {
      "displayName": "Marco Valentino",
      "userId": "16985191850808964577"
     },
     "user_tz": 0
    },
    "id": "j6Jb-1KgipEr",
    "outputId": "3a09f038-b155-4f13-bdd7-6eb0b40aadc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Critique Evaluation\n",
      "\n",
      " ================ Coherence ================\n",
      "\n",
      "Explanation 1:  {'entailment': 0.8770275115966797, 'neutral': 0.11719416081905365, 'contradiction': 0.00577832106500864, 'score': 0.871249190531671}\n",
      "Explanation 2:  {'entailment': 0.0783476543923219, 'neutral': 0.9102492133776346, 'contradiction': 0.011403123925750455, 'score': 0.06694453046657145}\n",
      "Coherence comparision: Explanation 1: 0.871249190531671 vs. Explanation 2: 0.06694453046657145\n",
      "Explanation 1 is therefore more coherent than Explanation 2.\n",
      "\n",
      "================ Parsimony ================\n",
      "\n",
      "Explanation 1:  {'score': 3}\n",
      "Explanation 2:  {'score': 6}\n",
      "\n",
      "Parsimony comparision: Explanation 1: 3 vs. Explanation 2: 6\n",
      "Explanation 1 is therefore more parsimonious than Explanation 2.\n",
      "\n",
      "================ Uncertainty ================\n",
      "\n",
      "Explanation 1:  {'score': 1.0230472882588706}\n",
      "Explanation 2:  {'score': 2.125597596168518}\n",
      "\n",
      "Uncertainty comparision: Explanation 1: 1.0230472882588706 vs. Explanation 2: 2.125597596168518\n",
      "Explanation 2 is therefore more uncertain than Explanation 1.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialise the soft critique models\n",
    "coherence = CoherenceCritique()\n",
    "parsimony = ParsimonyCritique()\n",
    "uncertainty = UncertaintyCritique()\n",
    "\n",
    "print(\"Soft Critique Evaluation\")\n",
    "# Calculate and display soft critique scores\n",
    "\n",
    "# Coherence Metrics\n",
    "exp1_coherence = coherence.critique(explanation_1)\n",
    "exp2_coherence = coherence.critique(explanation_2)\n",
    "\n",
    "print(\"\\n ================ Coherence ================\\n\")\n",
    "\n",
    "print(\"Explanation 1: \", exp1_coherence)\n",
    "print(\"Explanation 2: \", exp2_coherence)\n",
    "\n",
    "print(f\"Coherence comparision: Explanation 1: {exp1_coherence['score']} vs. Explanation 2: {exp2_coherence['score']}\")\n",
    "\n",
    "if exp1_coherence['score'] > exp2_coherence['score']:\n",
    "    print(\"Explanation 1 is therefore more coherent than Explanation 2.\")\n",
    "else:\n",
    "    print(\"Explanation 2 is the most coherente than Explanation 1.\")\n",
    "\n",
    "# Parsimony Metrics\n",
    "exp1_parsimony = parsimony.critique(hypothesis_1, conclusion_1, explanation_1)\n",
    "exp2_parsimony = parsimony.critique(hypothesis_2, conclusion_2, explanation_2)\n",
    "\n",
    "print(\"\\n================ Parsimony ================\\n\")\n",
    "\n",
    "print(\"Explanation 1: \", exp1_parsimony)\n",
    "print(\"Explanation 2: \", exp2_parsimony)\n",
    "\n",
    "print(f\"\\nParsimony comparision: Explanation 1: {exp1_parsimony['score']} vs. Explanation 2: {exp2_parsimony['score']}\")\n",
    "\n",
    "if exp1_parsimony['score'] < exp2_parsimony['score']:\n",
    "    print(\"Explanation 1 is therefore more parsimonious than Explanation 2.\")\n",
    "else:\n",
    "    print(\"Explanation 2 is therefore more parsimonious than Explanation 1.\")\n",
    "\n",
    "# Uncertainty Metrics\n",
    "exp1_uncertainty = uncertainty.critique(explanation_1)\n",
    "exp2_uncertainty = uncertainty.critique(explanation_2)\n",
    "\n",
    "print(\"\\n================ Uncertainty ================\\n\")\n",
    "\n",
    "print(\"Explanation 1: \", exp1_uncertainty)\n",
    "print(\"Explanation 2: \", exp2_uncertainty)\n",
    "\n",
    "print(f\"\\nUncertainty comparision: Explanation 1: {exp1_uncertainty['score']} vs. Explanation 2: {exp2_uncertainty['score']}\")\n",
    "\n",
    "if exp1_uncertainty['score'] > exp2_uncertainty['score']:\n",
    "    print(\"Explanation 1 is therefore more uncertain than Explanation 2.\")\n",
    "else:\n",
    "    print(\"Explanation 2 is therefore more uncertain than Explanation 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion \n",
    "\n",
    "The explanations generated by GPT-4-o for this example have a better \"separation\" than the ones generated by GPT-3.5-turbo.\n",
    "\n",
    "GPT-4-o:\n",
    "\n",
    "- Coherence comparision: Explanation 1: 0.871249190531671 vs. Explanation 2: 0.06694453046657145\n",
    "- Parsimony comparision: Explanation 1: 3 vs. Explanation 2: 6\n",
    "- Uncertainty comparision: Explanation 1: 1.0230472882588706 vs. Explanation 2: 2.125597596168518\n",
    "\n",
    "GPT-3.5-turbo:\n",
    "\n",
    "- Coherence comparision: Explanation 1: 0.871249190531671 vs. Explanation 2: 0.06694453046657145\n",
    "- Parsimony comparision: Explanation 1: 3 vs. Explanation 2: 4\n",
    "- Uncertainty comparision: Explanation 1: 1.0384624799092612 vs. Explanation 2: 1.1498368382453918"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1beM923HvLSUEf6eJ-bSOaqx9ICx7Fr_b",
     "timestamp": 1730906628931
    }
   ]
  },
  "kernelspec": {
   "display_name": "demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
